{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20201211_NC_CountCells_CA_2_8_ImprovedLoss.ipynb","provenance":[{"file_id":"1DdBgaOtQ4U7XjHOfADUJf0akIn92LUHZ","timestamp":1607705721216},{"file_id":"1L2o5A2vko0-KWNNTaELBAjjlvZ2wGN8i","timestamp":1607617282280},{"file_id":"1nvJ3L0U0FP5orhNrtx-TWm-oJ4wAbZsP","timestamp":1607613928447}],"collapsed_sections":[],"authorship_tag":"ABX9TyMfyhBDpfnQcauUWD8HuNVv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-1wywoxncZg","executionInfo":{"status":"ok","timestamp":1607705844423,"user_tz":0,"elapsed":19279,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"390cadb1-b37b-455e-8c3c-e4ca6f47db31"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","folder = 'drive/MyDrive/Code/Python/Collab/Cellular Automata 2020'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hABGFBCmvy-","executionInfo":{"status":"ok","timestamp":1607705859307,"user_tz":0,"elapsed":11202,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"b8fb200b-ab4c-4b63-b6c9-ea3d54026f69"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import matplotlib.colors as cl\n","from tensorflow.keras.layers import Conv2D\n","from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n","import moviepy.editor as mvp\n","import platform, tqdm\n","import PIL.Image, PIL.ImageDraw\n","from IPython.display import Image, clear_output\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n","Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n","Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3727360/45929032 bytes (8.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7831552/45929032 bytes (17.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11829248/45929032 bytes (25.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15654912/45929032 bytes (34.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19570688/45929032 bytes (42.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23683072/45929032 bytes (51.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27615232/45929032 bytes (60.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31735808/45929032 bytes (69.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35905536/45929032 bytes (78.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39985152/45929032 bytes (87.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b44105728/45929032 bytes (96.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n","  Done\n","File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 3855732441287592905\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 5733431555021315877\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 11970643506068579529\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14640891840\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 3703294548560691739\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19AJU76LnEUZ"},"source":["JustTesting = True # If True run everything faster\n","\n","LoadPreviousModelQ = False # if True we load the model, either for further training or just testing\n","i_step_load = 360000\n","\n","RunTrainingQ = False # If True we run the training\n","\n","RebuildDatasetQ = False # if True we rebuild the dataset\n","MutateTrainingQ = True # if True, during training we mutate the image\n","MutateTestingQ = True # if True, during testing we mutate the image\n","\n","i_step_verify = [] #[240000, 500000]\n","RunTestQ = True # if True, in the end we test an increasing size of inputs\n","\n","no_channels = '4TimesClasses' # 'SameClasses' '5PlusClasses' '4TimesClasses'\n","\n","dataset = 'count_digits'\n","id_run = 'CA_CD_3Classes_Deeper_M{}_MutTrain{}_MutTest{}'.format(no_channels, MutateTrainingQ, MutateTestingQ) # the prefix to all file names which will be use for saving and loading the model\n","\n","NO_CLASSES = 3\n","limits_classes = [2, 8] #len of this should be NO_CLASSES-1\n","limits_c_p = [0, 2, 8, 100]\n","H, W = 10, 10\n","\n","TR_EVOLVE = 50 # Number of time steps to let CA evolve for each input during training\n","TST_EVOLVE = 50 # Number of time steps to let CA evolve for each input during testing\n","\n","BATCH_SIZE = 64 # number of images per batch\n","\n","\n","if no_channels == 'SameClasses':\n","    NO_CHANNELS = NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '4TimesClasses':\n","    NO_CHANNELS = 4 * NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '5PlusClasses':\n","    NO_CHANNELS = 5 + NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","    \n","if JustTesting:\n","    TR_NO_ITERATIONS = 500 # number of iterations for the training loop\n","    export_every = 250 # number of iterations between each model export\n","    visualise_every = 50 # number of iteration between each model visualisation\n","else:\n","    TR_NO_ITERATIONS = 500000 # number of iterations for the training loop\n","    export_every = 10000 # number of iterations between each model export\n","    visualise_every = 2000 # number of iteration between each model visualisation\n","\n","ADD_NOISE = True # if True then the normal update of the CA has noise added"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w74lszBFnv3f","executionInfo":{"status":"ok","timestamp":1607705457241,"user_tz":0,"elapsed":7917,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"3d7318e0-8e61-44d6-d389-0a7dedeaad6d"},"source":["class CAModel(tf.keras.Model):\n","    \n","    def __init__(self, add_noise=ADD_NOISE):\n","        super().__init__()\n","        self.add_noise = add_noise\n","\n","        self.update_state = tf.keras.Sequential([\n","            Conv2D(80, 3, activation=tf.nn.relu, padding=\"SAME\"),\n","            Conv2D(120, 1, activation=tf.nn.relu, padding=\"SAME\"),\n","            Conv2D(NO_CHANNELS, 1, activation=None, padding=\"SAME\"),\n","        ])\n","        \n","        self(tf.zeros([1, H, W, 1 + NO_CHANNELS])) # dummy call to build the model\n","    \n","    @tf.function\n","    def call(self, x):\n","        '''\n","        this function updates the CA for one cycle\n","        x is the current CA state. its shape is (batch_size, H, W, no_channels). \n","            batch_size is BATCH_SIZE.\n","            no_channels is 1 + NO_CHANNELS, \n","                where the first is the gray image, \n","                the last NO_CLASSES are the classification predictions,\n","                and the others are there just for fun :)\n","        '''\n","        ds = self.update_state(x) # ds will be the state update (of course, we don't want to update the gray image as that is our true input)\n","        image, state = tf.split(x, [1, NO_CHANNELS], -1)\n","        if self.add_noise:\n","            residual_noise = tf.random.normal(tf.shape(ds), mean=0., stddev=0.02)\n","            ds += residual_noise\n","\n","        ds *= image \n","        state += ds\n","\n","        return tf.concat([image, state], -1)\n","\n","    @tf.function\n","    def initialize(self, images):\n","        '''\n","        input: images of size (batch, h, w)\n","        output: initial CA state full of 0's for positions other than the images. shape (batch, h, w, 1 + channel_n)\n","        '''\n","        state = tf.zeros([tf.shape(images)[0], H, W, NO_CHANNELS]) # size (batch, h, w, channel_n) full of zeros\n","        images = tf.reshape(images, [-1, H, W, 1]) # our images we add an extra dimension\n","        return tf.concat([images, state], -1) # just concatenating\n","\n","    @tf.function\n","    def classify(self, x):\n","        '''\n","        The last NO_CLASSES layers are the classification predictions, one channel\n","        per class.\n","        '''\n","        return x[:, :, :, -NO_CLASSES:]\n","    \n","    @tf.function\n","    def mutate(self, x, new_images):\n","        '''\n","        This function corrupts the current state of the CA by just changing the gray image\n","        '''\n","        image, state = tf.split(x, [1, NO_CHANNELS], -1)\n","        return tf.concat([new_images, state], -1)\n","\n","CAModel().update_state.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (1, 10, 10, 80)           9440      \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (1, 10, 10, 120)          9720      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (1, 10, 10, 12)           1452      \n","=================================================================\n","Total params: 20,612\n","Trainable params: 20,612\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RRKLHEE9nxhs"},"source":["# Training utilities\n","@tf.function\n","def individual_l2_loss(x, y):\n","    '''\n","    x is the current CA state vector. its shape is (batch_size, height, width, no_channels).\n","    y is the correct label out of NO_CLASSES possibilities. its shape is (batch_size, height, width, NO_CLASSES) (one-hot)\n","    '''\n","    t = y - ca.classify(x) # basically we want 1's for the correct and 0s for the incorrect digit. its shape is (batch_size, height, width, NO_CLASSES) (one-hot)\n","    error_batch = tf.reduce_sum(t ** 2, [1, 2, 3]) / 2\n","    no_pixels = tf.reduce_sum(y, [1, 2, 3])\n","    error_normalised_batch = error_batch / no_pixels\n","    return error_normalised_batch\n","\n","@tf.function\n","def batch_l2_loss(x, y, label_vector):\n","    '''\n","    x is the current CA state vector. its shape is (batch_size, height, width, no_channels).\n","    y is the correct label out of 10 possibilities. its shape is (batch_size, height, width, 10) (one-hot)\n","    returns the mean of the loss function\n","    '''\n","    i_l = individual_l2_loss(x, y)\n","    class_loss = []\n","    for i in range(NO_CLASSES):\n","        idx = tf.where((label_vector > (i - 0.5)) & (label_vector < (i + 0.5)))\n","        gather = tf.gather(i_l, tf.reshape(idx, (-1,)))\n","        class_loss.append(tf.reduce_mean(gather))\n","    return tf.reduce_mean(i_l), class_loss\n","\n","lr = 1e-3 # initial learning rate\n","lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([int(TR_NO_ITERATIONS*0.3), int(TR_NO_ITERATIONS*0.7)], [lr, lr*0.1, lr*0.01])\n","trainer = tf.keras.optimizers.Adam(lr_sched) # use ADAM optimizer with learning rate schedule\n","\n","loss_log = np.zeros(TR_NO_ITERATIONS) # for plotting of loss function across time\n","loss_log_classes = np.zeros((TR_NO_ITERATIONS, NO_CLASSES)) # for plotting of loss function across time\n","\n","def export_model(ca, i, loss_log, loss_log_classes):\n","    '''\n","    Saves the models parameters in file name base_fn\n","    '''\n","    ca.save_weights(folder + '/CA/' + id_run + '_run_no_{}'.format(i))\n","    np.savez(folder + '/CA/' + id_run + '_run_no_{}_loss'.format(i), loss_log=loss_log, loss_log_classes=loss_log_classes)\n","\n","def get_model(i):\n","    ca = CAModel(add_noise=ADD_NOISE)\n","    ca.load_weights(folder + '/CA/' + id_run + '_run_no_{}'.format(i))\n","    res = np.load(folder + '/CA/' + id_run + '_run_no_{}_loss.npz'.format(i))\n","    loss_log = res['loss_log']\n","    loss_log_classes = res['loss_log_classes']\n","    return ca, loss_log, loss_log_classes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7_rEDIsnzhv"},"source":["# Visualization utilities\n","\n","def zoom(img, scale=4):\n","    '''\n","    Takes an image array and increases its resolution by simply repeating the values\n","    '''\n","    img = np.repeat(img, scale, 0)\n","    img = np.repeat(img, scale, 1)\n","    return img\n","\n","def tile2d(a, w=None):\n","    a = np.asarray(a)\n","    if w is None:\n","        w = int(np.ceil(np.sqrt(len(a))))\n","    th, tw = a.shape[1:3]\n","    pad = (w-len(a))%w\n","    a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n","    h = len(a)//w\n","    a = a.reshape([h, w]+list(a.shape[1:]))\n","    a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n","    return a\n","\n","def np2pil(a):\n","    # Covert Numpy array of floats into ints\n","    if a.dtype in [np.float32, np.float64]:\n","        a = np.uint8(np.clip(a, 0, 1) * 255)\n","    return PIL.Image.fromarray(a)\n","\n","def imwrite(f, a, fmt=None):\n","    # Save numpy array a as image in the disk with filename f\n","    a = np.asarray(a)\n","    if isinstance(f, str):\n","        fmt = f.rsplit('.', 1)[-1].lower()\n","        if fmt == 'jpg':\n","            fmt = 'jpeg'\n","        f = open(f, 'wb')\n","    np2pil(a).save(f, fmt, quality=95)\n","\n","def imencode(a, fmt='jpeg'):\n","    '''\n","    a is the array/tensor to be encoded\n","    fmt = fileformat\n","    '''\n","    a = np.asarray(a)\n","    if len(a.shape) == 3 and a.shape[-1] == 4:\n","        fmt = 'png'\n","    f = io.BytesIO()\n","    imwrite(f, a, fmt)\n","    return f.getvalue()\n","\n","def imshow(a, fmt='jpeg'):\n","    '''\n","    a is the array/tensor to be plotted\n","    fmt = fileformat\n","    '''\n","    display(Image(data=imencode(a, fmt)))\n","\n","\n","# colors = np.array([cl.to_rgba_array(plt.cm.tab10(i))[0, :3] * 255 for i in range(10)]).astype(int)\n","# \n","color_lookup = tf.constant([\n","                    [255, 0, 0],\n","                    [0, 255, 0],\n","                    [0, 0, 255],\n","                    [0, 0, 0], # This is the default for digits.\n","                    [255, 255, 255] # This is the background.\n","                    ])\n","\n","def color_labels(x, output_x, dtype=tf.uint8):\n","    '''\n","    input x grayscale image: its shape is ([batch_size, ]height, width)\n","    input output_x: the output of the CA for the image x. its shape seems to be ([batch_size, ]height, width, 10)\n","    '''\n","    is_alive = x # 1 if pixel is alive, 0 if background. its shape ([b, ]h, w)\n","    is_background = 1. - x # 0 if pixel is alive, 1 if background. its shape ([b, ]h, w)\n","    output_x = output_x * tf.expand_dims(is_alive, -1) # forcibly cancels everything outside of it. y_pic will be 0 for dead pixels. and the previous value for the alive pixels\n","    \n","    black_and_bg = tf.fill(list(x.shape) + [2], 0.01) # an array filled with 0.01 of shape ([b, ]h, w, 2). 0.01 is the minimum value for outputs to be considered\n","    black_and_bg *= tf.stack([is_alive, is_background], -1) # an array filled with 0.01 and 0's depending on alive status. of shape ([b, ]h, w, 2)\n","\n","    number_or_background =  tf.concat([output_x, black_and_bg], -1) # the voting for the 12 different categories. (10 colors + original grayscale and background. its shape is ([b, ]h, w, 12)\n","    classified_pixels = tf.argmax(number_or_background, -1) # the result of the vote.  its shape is ([b, ]h, w)\n","    rgb_pixels = tf.gather(color_lookup, classified_pixels) # And now I suppose this shape is ([b, ]h, w, 3)\n","    if dtype == tf.uint8:\n","        return tf.cast(rgb_pixels, tf.uint8)\n","    else:\n","        return tf.cast(rgb_pixels, dtype) / 255.\n","\n","def classify_and_color(ca, x):\n","    '''\n","    input ca: the CA class instance with proper architecture and learned weights\n","    input x: a state of the CA. its shape is (batch_size, height, width, no_channels).\n","    output: \n","    '''\n","    current_image = x[:, :, :, 0]\n","    output_ca = ca.classify(x) # x[:, :, :, -NO_CLASSES:] shape = (b, h, w, NO_CLASSES) where we want values 0 if not that number and 1 if that number\n","    return color_labels(current_image, output_ca, dtype=tf.float32)\n","\n","def visualize_batch(ca, x0, x, step_i):\n","    '''\n","    input ca: the CA class instance with proper architecture and learned weights\n","    input x0: the initial state in the learning step. its shape is (batch_size, height, width, no_channels).\n","    input x: the final state. its shape is (batch_size, height, width, no_channels).\n","\n","    '''\n","    vis0 = np.hstack(classify_and_color(ca, x0).numpy()) # create horizontally the batch with proper colors\n","    vis1 = np.hstack(classify_and_color(ca, x).numpy())\n","    vis = np.vstack([vis0, vis1]) # before and after the steps\n","    imwrite(folder + '/CA/batches_%04d.jpg'%step_i, vis)\n","    imshow(vis)\n","\n","def plot_loss(loss_log, loss_log_classes, save=False):\n","    plt.figure(figsize=(10, 4))\n","    plt.title('Loss history (log10)')\n","    x = loss_log\n","    plt.plot(np.log10(loss_log), '.', alpha=0.1)\n","    for i in range(NO_CLASSES):\n","        if loss_log_classes.shape[0] > 0:\n","            plt.plot(np.log10(loss_log_classes[:, i]), alpha=0.5, label='{}<pixels<={}'.format(limits_c_p[i], limits_c_p[i+1]), color=color_lookup[i].numpy()/255)\n","    plt.legend()\n","    if save:\n","        plt.savefig(folder + '/CA/log_loss_{}'.format(id_run))\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"heVd45xmn-M_"},"source":["# Prepare the dataset\n","size_ds = 10000\n","\n","def get_next_pixel(base_pixel, positions_colored):\n","    x, y = base_pixel[0], base_pixel[1]\n","    keep_going = 1\n","    j = 0\n","    while keep_going and j < 10:\n","        j += 1\n","        x_or_y = np.random.rand() < 0.5\n","        pos_or_neg = np.random.rand() < 0.5\n","        if x_or_y:\n","            if pos_or_neg:\n","                dx = 1\n","                dy = 0\n","            else:\n","                dx = -1\n","                dy = 0\n","        else:\n","            if pos_or_neg:\n","                dx = 0\n","                dy = 1\n","            else:\n","                dx = 0\n","                dy = -1\n","        nx = min(max(0, x + dx), 9)\n","        ny = min(max(0, y + dy), 9)\n","        test_pixel = [nx, ny]\n","        if test_pixel in positions_colored:\n","            pass\n","        else:\n","            return 1, test_pixel\n","    return 0, [0, 0]\n","\n","BuildDS = False\n","if RebuildDatasetQ:\n","    BuildDS = True\n","else:\n","    try:\n","        res = np.load(folder + '/CA/{}_{}.npz'.format(dataset, size_ds))\n","        x_train = res['x_train']\n","        y_train = res['y_train']\n","        x_test = res['x_test']\n","        y_test = res['y_test']\n","    except:\n","        BuildDS = True\n","if BuildDS:\n","    X = np.zeros((size_ds, H, W), np.float32)\n","    Y = np.zeros((size_ds), np.float32)\n","    \n","    for i in range(size_ds):\n","        no_pixels = np.random.randint(20)\n","        pixels_placed = 1\n","        first_pixel = [4, 4]\n","        positions_colored = [first_pixel]\n","        X[i, first_pixel[0], first_pixel[1]] = 1\n","        for j in range(no_pixels - 1):\n","            base_pixel = positions_colored[np.random.choice(len(positions_colored))]\n","            sucess, next_pixel = get_next_pixel(base_pixel, positions_colored)\n","            if sucess:\n","                pixels_placed += 1\n","                positions_colored.append(next_pixel)\n","                X[i, next_pixel[0], next_pixel[1]] = 1\n","        Y[i] = pixels_placed\n","        x_train, x_test = np.split(X, [int(size_ds*0.8)])\n","        y_train, y_test = np.split(Y, [int(size_ds*0.8)])\n","    \n","\n","    np.savez(folder + '/CA/{}_{}.npz'.format(dataset, size_ds), x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n","    \n","def class_indice_f(no_pixels):\n","    indices = np.where(no_pixels <= np.array(limits_classes))[0]\n","    if indices.shape[0] == 0:\n","        return NO_CLASSES-1\n","    else:\n","        return indices[0]\n","\n","def to_classes_dim_label(x, y):\n","    '''\n","    input x shape is (no_images, height, width)\n","    input y shape is (no_images,)\n","    output: y_res (no_images, height, width, NO_CLASSES) y_res[b, h, w, i] = 1 if the image b is digit i, and only at the positions h, w where it is alive\n","    '''\n","    y_res = np.zeros(list(x.shape) + [NO_CLASSES])\n","    y_expanded = np.broadcast_to(y, x.T.shape).T # broadcast y to match x shape:\n","    for i in range(x.shape[0]):\n","        class_indice = class_indice_f(y[i])\n","        y_res[i, :, :, class_indice] = x[i, :, :]\n","    return y_res.astype(np.float32)\n","\n","\n","y_train_pic = to_classes_dim_label(x_train, y_train)\n","y_label_train = np.zeros(y_train.shape[0])\n","for i in range(y_train.shape[0]):\n","    y_label_train[i] = class_indice_f(y_train[i])\n","# y_test_pic = to_classes_dim_label(x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgNuQfis7p4g"},"source":["if LoadPreviousModelQ:\n","    ca, loss_log, loss_log_classes = get_model(i_step_load)\n","    ITER = i_step_load\n","else:\n","    ca = CAModel()\n","    ITER = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcMsi_PmoEVD"},"source":["# Training happens here\n","if RunTrainingQ:\n","    # Training Step\n","    @tf.function\n","    def train_step(x, y, y_label, MutateTrainingQ=False):\n","        '''\n","        x is the current CA state. its shape is (batch_size, height, width, no_channels).\n","        y is the correct label out of 10 possibilities. its shape is (batch_size, ?)\n","        '''\n","        iter_n = max(2, np.random.randint(TR_EVOLVE)) # Number of initial iterations of the CA for each training step\n","        with tf.GradientTape() as g: # GradientTape does automatic differentiation on the learnable_parameters of our model\n","            for i_iter in tf.range(iter_n): # Basically let time evolve\n","                x = ca(x) # update the CA according to call method? ca(x) = ca.call(x)?\n","            loss_b, c_l_b = batch_l2_loss(x, y, y_label) # compute the scalar loss\n","        grads = g.gradient(loss_b, ca.weights) # Gradient Tape and Keras doing its magic\n","        grads = [g/(tf.norm(g)+1e-8) for g in grads] # Normalising the gradients uh?\n","        trainer.apply_gradients(zip(grads, ca.weights)) # Keras and ADAM magic \n","        \n","        if MutateTrainingQ:\n","            c_i = x[:, :, :, 0]\n","            x = ca.mutate(x, tf.expand_dims(tf.random.shuffle(c_i), -1))\n","        \n","        iter_n = TR_EVOLVE - iter_n # Number of iterations of the CA for each training step\n","        with tf.GradientTape() as g: # GradientTape does automatic differentiation on the learnable_parameters of our model\n","            for i_iter in tf.range(iter_n): # Basically let time evolve\n","                x = ca(x) # update the CA according to call method? ca(x) = ca.call(x)?\n","            loss_a, c_l_a = batch_l2_loss(x, y, y_label) # compute the scalar loss\n","        grads = g.gradient(loss_a, ca.weights) # Gradient Tape and Keras doing its magic\n","        grads = [g/(tf.norm(g)+1e-8) for g in grads] # Normalising the gradients uh?\n","        trainer.apply_gradients(zip(grads, ca.weights)) # Keras and ADAM magic \n","        return x, loss_b + loss_a, [c_l_b[i_list] + c_l_a[i_list] for i_list in range(NO_CLASSES)]\n","\n","    # Training Loop\n","    for i in range(ITER, TR_NO_ITERATIONS):\n","\n","        b_idx = np.random.randint(0, x_train.shape[0] - 1, size=BATCH_SIZE)\n","        x0 = ca.initialize(x_train[b_idx])\n","        y0 = y_train_pic[b_idx]\n","        y0_label = y_label_train[b_idx]\n","        y0_label = tf.convert_to_tensor(y0_label)        \n","\n","        x, loss, c_l = train_step(x0, y0, y0_label)\n","\n","        loss_log[i] = loss.numpy()\n","        loss_log_classes[i, :] = [k.numpy() for k in c_l]\n","\n","        if i % visualise_every == 0:\n","            clear_output()\n","            plot_loss(loss_log[:i], loss_log_classes[:i, :], True)\n","        if i % export_every == 0:\n","            export_model(ca, i, loss_log, loss_log_classes)\n","\n","        print('\\r step: {}, log10(loss): {}, log10(loss)[classes]: {}'.format(i + 1, np.log10(loss), np.log10(c_l)), end='')\n","    export_model(ca, TR_NO_ITERATIONS, loss_log, loss_log_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DuQbZ6xZoCm9"},"source":["class VideoWriter:\n","    def __init__(self, filename, fps=30.0, **kw):\n","        self.writer = None\n","        self.params = dict(filename=filename, fps=fps, **kw)\n","\n","    def add(self, img):\n","        img = np.asarray(img)\n","        if self.writer is None:\n","            h, w = img.shape[:2]\n","            self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n","        if img.dtype in [np.float32, np.float64]:\n","            img = np.uint8(img.clip(0, 1)*255)\n","        if len(img.shape) == 2:\n","            img = np.repeat(img[..., None], 3, -1)\n","        if len(img.shape) == 3 and img.shape[-1] == 4:\n","            img = img[..., :3] * img[..., 3, None]\n","        self.writer.write_frame(img)\n","\n","    def close(self):\n","        if self.writer:\n","            self.writer.close()\n","\n","    def __enter__(self):\n","        return self\n","\n","    def __exit__(self, *kw):\n","        self.close()\n","\n","def make_run_videos(ca, eval_bs, i_step, seed=1):\n","    np.random.seed(seed)\n","    new_idx = np.random.randint(0, x_test.shape[0] - 1, size=eval_bs)\n","    x = ca.initialize(x_test[new_idx])\n","    with VideoWriter(folder + '/CA/Movie_model_{}_{}.mp4'.format(id_run, i_step)) as vid:\n","        for i in tqdm.trange(-1, TST_EVOLVE):\n","            if MutateTestingQ and i == int(TST_EVOLVE / 2):\n","                c_i = x[:, :, :, 0]\n","                x = ca.mutate(x, tf.expand_dims(tf.random.shuffle(c_i), -1))\n","#             true_images = tf.expand_dims(0.5 - 0 * x[:, :, :, 0], -1)\n","#             alphas = zoom(tile2d(true_images), scale=4)\n","#             print(alphas)\n","            if i == -1:\n","                image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","            else:\n","                x = ca(x)\n","                image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","#             new_image = np.concatenate((image, alphas), axis=-1)\n","#             print(new_image)\n","#             im = np.uint8(new_image*255)\n","            im = np.uint8(image*255)\n","            im = PIL.Image.fromarray(im)\n","            draw = PIL.ImageDraw.Draw(im)\n","            vid.add(np.uint8(im))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVj-aSSMt30x","executionInfo":{"status":"ok","timestamp":1607705528202,"user_tz":0,"elapsed":611,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"ecc4e4ab-b18e-4a1f-8c5b-d655174ac036"},"source":["ca"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<__main__.CAModel at 0x7f3647f06e80>,\n"," array([57.41350555,  7.63882589,  3.03335905, ...,  0.        ,\n","         0.        ,  0.        ]),\n"," array([[ 2.22993231, 37.75796127, 92.16165924],\n","        [ 0.90170944,  6.34681988, 10.06003284],\n","        [ 0.88766009,  2.69141102,  3.84651518],\n","        ...,\n","        [ 0.        ,  0.        ,  0.        ],\n","        [ 0.        ,  0.        ,  0.        ],\n","        [ 0.        ,  0.        ,  0.        ]]))"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"vV_WIAkvoGol","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607705560481,"user_tz":0,"elapsed":5192,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"04066d4c-4946-4b4a-b2cd-0fb93605ce3f"},"source":["eval_bs = 5 ** 2 # number of samples in a batch to evaluate\n","for i_step_v in i_step_verify:\n","    ca, loss_log, loss_log_classes = get_model(i_step_v)\n","    make_run_videos(ca, eval_bs, i_step_v)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 1/201 [00:00<00:32,  6.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function CAModel.call at 0x7f3647f1a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 201/201 [00:01<00:00, 198.98it/s]\n","100%|██████████| 201/201 [00:00<00:00, 231.42it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"3EZfTrwXoIj0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607705588238,"user_tz":0,"elapsed":7716,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"26295bb4-e540-4d22-88de-e504f1a9f9aa"},"source":["if RunTestQ:\n","    def add_pixel(old_image):\n","        new_image = old_image.copy()\n","        indices = np.asarray(np.where(old_image == 1)).T\n","        success = 0\n","        k = 0\n","        while (not success) or (k > 100):\n","            k += 1\n","            idx = np.random.randint(indices.shape[0])\n","            x, y = indices[idx, :]\n","            x_or_y = np.random.rand() < 0.5\n","            pos_or_neg = np.random.rand() < 0.5\n","            if x_or_y:\n","                if pos_or_neg:\n","                    dx = 1\n","                    dy = 0\n","                else:\n","                    dx = -1\n","                    dy = 0\n","            else:\n","                if pos_or_neg:\n","                    dx = 0\n","                    dy = 1\n","                else:\n","                    dx = 0\n","                    dy = -1\n","            nx = min(max(0, x + dx), 9)\n","            ny = min(max(0, y + dy), 9)\n","            if old_image[nx, ny] < 0.5:\n","                new_image[nx, ny] = 1\n","                success = 1\n","        return new_image\n","\n","    images = np.zeros((20, 25, H, W), dtype=np.float32)\n","    for i_img in range(25):\n","        images[0, i_img, int(H / 2), int(W / 2)] = 1\n","    for j in range(1, 20):\n","        for i_img in range(25):\n","            images[j, i_img, :, :] = add_pixel(images[j - 1, i_img, :, :])\n","    images = tf.constant(images)\n","    \n","    for i_step_v in i_step_verify:\n","        ca, loss_log, loss_log_classes = get_model(i_step_v)\n","        x = ca.initialize(images[0, :, :, :])\n","        with VideoWriter(folder + '/CA/Movie_test_increase_{}_{}.mp4'.format(id_run, i_step_v)) as vid:\n","            for j in range(20):\n","                x = ca.mutate(x, tf.expand_dims(images[j, :, :, :], -1))\n","                for i in tqdm.trange(TR_EVOLVE):\n","                    x = ca(x)\n","                    image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","                    im = np.uint8(image*255)\n","                    im = PIL.Image.fromarray(im)\n","                    draw = PIL.ImageDraw.Draw(im)\n","                    vid.add(np.uint8(im))\n","        x = ca.initialize(images[0, :, :, :])\n","        with VideoWriter(folder + '/CA/Movie_test_decrease_{}_{}.mp4'.format(id_run, i_step_v)) as vid:\n","            for j in range(20):\n","                x = ca.mutate(x, tf.expand_dims(images[19 - j, :, :, :], -1))\n","                for i in tqdm.trange(TR_EVOLVE):\n","                    x = ca(x)\n","                    image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","                    im = np.uint8(image*255)\n","                    im = PIL.Image.fromarray(im)\n","                    draw = PIL.ImageDraw.Draw(im)\n","                    vid.add(np.uint8(im))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 20/20 [00:00<00:00, 91.32it/s]\n","100%|██████████| 20/20 [00:00<00:00, 323.84it/s]\n","100%|██████████| 20/20 [00:00<00:00, 290.73it/s]\n","100%|██████████| 20/20 [00:00<00:00, 295.42it/s]\n","100%|██████████| 20/20 [00:00<00:00, 301.42it/s]\n","100%|██████████| 20/20 [00:00<00:00, 287.15it/s]\n","100%|██████████| 20/20 [00:00<00:00, 292.55it/s]\n","100%|██████████| 20/20 [00:00<00:00, 300.41it/s]\n","100%|██████████| 20/20 [00:00<00:00, 246.58it/s]\n","100%|██████████| 20/20 [00:00<00:00, 287.89it/s]\n","100%|██████████| 20/20 [00:00<00:00, 297.14it/s]\n","100%|██████████| 20/20 [00:00<00:00, 272.67it/s]\n","100%|██████████| 20/20 [00:00<00:00, 261.52it/s]\n","100%|██████████| 20/20 [00:00<00:00, 272.00it/s]\n","100%|██████████| 20/20 [00:00<00:00, 271.32it/s]\n","100%|██████████| 20/20 [00:00<00:00, 249.19it/s]\n","100%|██████████| 20/20 [00:00<00:00, 269.95it/s]\n","100%|██████████| 20/20 [00:00<00:00, 277.88it/s]\n","100%|██████████| 20/20 [00:00<00:00, 286.34it/s]\n","100%|██████████| 20/20 [00:00<00:00, 256.60it/s]\n","100%|██████████| 20/20 [00:00<00:00, 124.76it/s]\n","100%|██████████| 20/20 [00:00<00:00, 334.96it/s]\n","100%|██████████| 20/20 [00:00<00:00, 292.14it/s]\n","100%|██████████| 20/20 [00:00<00:00, 268.65it/s]\n","100%|██████████| 20/20 [00:00<00:00, 274.74it/s]\n","100%|██████████| 20/20 [00:00<00:00, 298.74it/s]\n","100%|██████████| 20/20 [00:00<00:00, 309.80it/s]\n","100%|██████████| 20/20 [00:00<00:00, 297.06it/s]\n","100%|██████████| 20/20 [00:00<00:00, 295.52it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.88it/s]\n","100%|██████████| 20/20 [00:00<00:00, 276.63it/s]\n","100%|██████████| 20/20 [00:00<00:00, 287.01it/s]\n","100%|██████████| 20/20 [00:00<00:00, 277.17it/s]\n","100%|██████████| 20/20 [00:00<00:00, 297.24it/s]\n","100%|██████████| 20/20 [00:00<00:00, 289.24it/s]\n","100%|██████████| 20/20 [00:00<00:00, 279.86it/s]\n","100%|██████████| 20/20 [00:00<00:00, 248.84it/s]\n","100%|██████████| 20/20 [00:00<00:00, 293.79it/s]\n","100%|██████████| 20/20 [00:00<00:00, 304.78it/s]\n","100%|██████████| 20/20 [00:00<00:00, 301.63it/s]\n","100%|██████████| 20/20 [00:00<00:00, 94.01it/s]\n","100%|██████████| 20/20 [00:00<00:00, 328.68it/s]\n","100%|██████████| 20/20 [00:00<00:00, 268.72it/s]\n","100%|██████████| 20/20 [00:00<00:00, 269.76it/s]\n","100%|██████████| 20/20 [00:00<00:00, 286.65it/s]\n","100%|██████████| 20/20 [00:00<00:00, 261.66it/s]\n","100%|██████████| 20/20 [00:00<00:00, 270.59it/s]\n","100%|██████████| 20/20 [00:00<00:00, 272.05it/s]\n","100%|██████████| 20/20 [00:00<00:00, 268.91it/s]\n","100%|██████████| 20/20 [00:00<00:00, 284.72it/s]\n","100%|██████████| 20/20 [00:00<00:00, 284.88it/s]\n","100%|██████████| 20/20 [00:00<00:00, 263.75it/s]\n","100%|██████████| 20/20 [00:00<00:00, 284.58it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.75it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.86it/s]\n","100%|██████████| 20/20 [00:00<00:00, 287.89it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.83it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.91it/s]\n","100%|██████████| 20/20 [00:00<00:00, 234.13it/s]\n","100%|██████████| 20/20 [00:00<00:00, 240.58it/s]\n","100%|██████████| 20/20 [00:00<00:00, 121.78it/s]\n","100%|██████████| 20/20 [00:00<00:00, 315.71it/s]\n","100%|██████████| 20/20 [00:00<00:00, 274.59it/s]\n","100%|██████████| 20/20 [00:00<00:00, 298.62it/s]\n","100%|██████████| 20/20 [00:00<00:00, 294.48it/s]\n","100%|██████████| 20/20 [00:00<00:00, 256.61it/s]\n","100%|██████████| 20/20 [00:00<00:00, 246.78it/s]\n","100%|██████████| 20/20 [00:00<00:00, 263.34it/s]\n","100%|██████████| 20/20 [00:00<00:00, 265.11it/s]\n","100%|██████████| 20/20 [00:00<00:00, 243.66it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.11it/s]\n","100%|██████████| 20/20 [00:00<00:00, 276.50it/s]\n","100%|██████████| 20/20 [00:00<00:00, 282.71it/s]\n","100%|██████████| 20/20 [00:00<00:00, 266.47it/s]\n","100%|██████████| 20/20 [00:00<00:00, 276.45it/s]\n","100%|██████████| 20/20 [00:00<00:00, 286.37it/s]\n","100%|██████████| 20/20 [00:00<00:00, 275.62it/s]\n","100%|██████████| 20/20 [00:00<00:00, 285.09it/s]\n","100%|██████████| 20/20 [00:00<00:00, 295.30it/s]\n","100%|██████████| 20/20 [00:00<00:00, 295.13it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OjQpvGShoKcO"},"source":[""],"execution_count":null,"outputs":[]}]}