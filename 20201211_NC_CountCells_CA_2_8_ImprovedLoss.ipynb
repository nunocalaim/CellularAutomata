{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20201211_NC_CountCells_CA_2_8_ImprovedLoss.ipynb","provenance":[{"file_id":"1DdBgaOtQ4U7XjHOfADUJf0akIn92LUHZ","timestamp":1607705721216},{"file_id":"1L2o5A2vko0-KWNNTaELBAjjlvZ2wGN8i","timestamp":1607617282280},{"file_id":"1nvJ3L0U0FP5orhNrtx-TWm-oJ4wAbZsP","timestamp":1607613928447}],"collapsed_sections":[],"authorship_tag":"ABX9TyMgMVeF7ys1awGnbCXBTj39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-1wywoxncZg","executionInfo":{"status":"ok","timestamp":1609861722516,"user_tz":0,"elapsed":485,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"67529ee0-a8d2-40be-89fd-3a8b52176716"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zo-knd3UDME_","executionInfo":{"status":"ok","timestamp":1609861724578,"user_tz":0,"elapsed":2540,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["folder = 'drive/MyDrive/Code/GitHub/CellularAutomata'\n","import sys\n","sys.path.insert(1, folder)\n","import ca_model\n","import count_pixels_dataset as cpd\n","import visualisation as vis_ca"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKLwI-jTx2By","executionInfo":{"status":"ok","timestamp":1609861724579,"user_tz":0,"elapsed":2538,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# import importlib\n","# importlib.reload(ca_model)\n","# importlib.reload(vis_ca)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"8hABGFBCmvy-","executionInfo":{"status":"ok","timestamp":1609861724580,"user_tz":0,"elapsed":2535,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["import numpy as np\n","# import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from IPython.display import clear_output\n","# import matplotlib.colors as cl\n","# # from tensorflow.keras.layers import Conv2D\n","# from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n","# import moviepy.editor as mvp\n","# import platform, tqdm\n","# import PIL.Image, PIL.ImageDraw\n","# from IPython.display import Image, clear_output\n","# from tensorflow.python.client import device_lib\n","# print(device_lib.list_local_devices())"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"19AJU76LnEUZ"},"source":["JustTesting = True # If True run everything faster\n","\n","LoadPreviousModelQ = False # if True we load the model, either for further training or just testing\n","i_step_load = 360000\n","\n","seed_training = 1\n","seed_movies = 1\n","\n","RunTrainingQ = True # If True we run the training\n","\n","RebuildDatasetQ = False # if True we rebuild the dataset\n","MutateTrainingQ = True # if True, during training we mutate the image\n","MutateTestingQ = True # if True, during testing we mutate the image\n","\n","RunTestQ = True # if True, in the end we test an increasing size of inputs\n","\n","no_channels = '4TimesClasses' # 'SameClasses' '5PlusClasses' '4TimesClasses'\n","\n","dataset = 'count_digits'\n","id_run = 'CA_CD_3Classes_Deeper_M{}_MutTrain{}_MutTest{}'.format(no_channels, MutateTrainingQ, MutateTestingQ) # the prefix to all file names which will be use for saving and loading the model\n","\n","NO_CLASSES = 3\n","limits_classes = [2, 8] #len of this should be NO_CLASSES-1\n","limits_c_p = [0, 2, 8, 100]\n","color_lookup = tf.constant([\n","                    [255, 0, 0],\n","                    [0, 255, 0],\n","                    [0, 0, 255],\n","                    [0, 0, 0], # This is the default for digits.\n","                    [255, 255, 255] # This is the background.\n","                    ])\n","\n","H, W = 10, 10\n","\n","TR_EVOLVE = 50 # Number of time steps to let CA evolve for each input during training\n","TST_EVOLVE = 50 # Number of time steps to let CA evolve for each input during testing\n","\n","BATCH_SIZE = 64 # number of images per batch\n","\n","if no_channels == 'SameClasses':\n","    NO_CHANNELS = NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '4TimesClasses':\n","    NO_CHANNELS = 4 * NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '5PlusClasses':\n","    NO_CHANNELS = 5 + NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","    \n","if JustTesting:\n","    TR_NO_ITERATIONS = 500 # number of iterations for the training loop\n","    export_every = 250 # number of iterations between each model export\n","    visualise_every = 50 # number of iteration between each model visualisation\n","    i_step_verify = [250, 500] # [250, 500]\n","else:\n","    TR_NO_ITERATIONS = 500000 # number of iterations for the training loop\n","    export_every = 10000 # number of iterations between each model export\n","    visualise_every = 2000 # number of iteration between each model visualisation\n","    i_step_verify = [240000, 500000] # [240000, 500000]\n","\n","\n","ADD_NOISE = True # if True then the normal update of the CA has noise added"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w74lszBFnv3f"},"source":["ca_model.CAModel(NO_CHANNELS, NO_CLASSES, H, W).update_state.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaExqYl-l_7w"},"source":["# Prepare the dataset\n","size_ds = 10000 #the number of images on the dataset\n","\n","BuildDS = False\n","if RebuildDatasetQ:\n","    BuildDS = True\n","else:\n","    try:\n","        res = np.load(folder + '/dataset/{}_{}.npz'.format(dataset, size_ds))\n","        x_train = res['x_train']\n","        y_train = res['y_train']\n","        x_test = res['x_test']\n","        y_test = res['y_test']\n","    except:\n","        BuildDS = True\n","if BuildDS:\n","    x_train, x_test, y_train, y_test = cpd.build_dataset(size_ds, H, W) \n","    np.savez(folder + '/dataset/{}_{}.npz'.format(dataset, size_ds), x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n","\n","y_train_pic = cpd.to_classes_dim_label(x_train, y_train, limits_classes)\n","y_label_train = np.zeros(y_train.shape[0])\n","for i in range(y_train.shape[0]):\n","    y_label_train[i] = cpd.class_indice_f(y_train[i], limits_classes)\n","# y_test_pic = to_classes_dim_label(x_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpiZdC5-P0ii"},"source":["lr = 1e-3 # initial learning rate\n","lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([int(TR_NO_ITERATIONS*0.3), int(TR_NO_ITERATIONS*0.7)], [lr, lr*0.1, lr*0.01])\n","trainer = tf.keras.optimizers.Adam(lr_sched) # use ADAM optimizer with learning rate schedule\n","\n","loss_log = np.zeros(TR_NO_ITERATIONS) # for plotting of loss function across time\n","loss_log_classes = np.zeros((TR_NO_ITERATIONS, NO_CLASSES)) # for plotting of loss function across time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgNuQfis7p4g"},"source":["if LoadPreviousModelQ:\n","    ca, loss_log, loss_log_classes = ca_model.get_model(folder, id_run, i_step_load, NO_CHANNELS, NO_CLASSES, H, W, ADD_NOISE)\n","\n","    ITER = i_step_load\n","else:\n","    ca = ca_model.CAModel(NO_CHANNELS, NO_CLASSES, H, W)\n","    ITER = 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcMsi_PmoEVD"},"source":["# Training happens here\n","np.random.seed(seed_training)\n","if RunTrainingQ:\n","    # Training Loop\n","    for i in range(ITER, TR_NO_ITERATIONS):\n","\n","        b_idx = np.random.randint(0, x_train.shape[0] - 1, size=BATCH_SIZE)\n","        x0 = ca.initialize(x_train[b_idx])\n","        y0 = y_train_pic[b_idx]\n","        y0_label = y_label_train[b_idx]\n","        y0_label = tf.convert_to_tensor(y0_label)        \n","\n","        x, loss, c_l = ca_model.train_step(trainer, ca, x0, y0, y0_label, TR_EVOLVE, NO_CLASSES, MutateTrainingQ=MutateTrainingQ)\n","\n","        loss_log[i] = loss.numpy()\n","        loss_log_classes[i, :] = [k.numpy() for k in c_l]\n","\n","        if i % visualise_every == 0:\n","            clear_output()\n","            vis_ca.plot_loss(loss_log[:i], loss_log_classes[:i, :], folder, id_run, limits_c_p, color_lookup, True)\n","        if i % export_every == 0:\n","            ca_model.export_model(folder, id_run, ca, i, loss_log, loss_log_classes)\n","\n","        print('\\r step: {}, log10(loss): {}, log10(loss)[classes]: {}'.format(i + 1, np.log10(loss), np.log10(c_l)), end='')\n","    ca_model.export_model(folder, id_run, ca, TR_NO_ITERATIONS, loss_log, loss_log_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vV_WIAkvoGol"},"source":["eval_bs = 5 ** 2 # number of samples to show in the movie\n","for i_step_v in i_step_verify:\n","    ca, loss_log, loss_log_classes = ca_model.get_model(folder, id_run, i_step_v, NO_CHANNELS, NO_CLASSES, H, W, ADD_NOISE)\n","\n","    np.random.seed(seed_movies)\n","\n","    new_idx = np.random.randint(0, x_test.shape[0] - 1, size=eval_bs)\n","    x = ca.initialize(x_test[new_idx])\n","\n","    vis_ca.make_run_videos(folder, id_run, i_step_v, TST_EVOLVE, MutateTestingQ, x, ca, color_lookup)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3EZfTrwXoIj0"},"source":["# if RunTestQ:\n","#     def add_pixel(old_image):\n","#         new_image = old_image.copy()\n","#         indices = np.asarray(np.where(old_image == 1)).T\n","#         success = 0\n","#         k = 0\n","#         while (not success) or (k > 100):\n","#             k += 1\n","#             idx = np.random.randint(indices.shape[0])\n","#             x, y = indices[idx, :]\n","#             x_or_y = np.random.rand() < 0.5\n","#             pos_or_neg = np.random.rand() < 0.5\n","#             if x_or_y:\n","#                 if pos_or_neg:\n","#                     dx = 1\n","#                     dy = 0\n","#                 else:\n","#                     dx = -1\n","#                     dy = 0\n","#             else:\n","#                 if pos_or_neg:\n","#                     dx = 0\n","#                     dy = 1\n","#                 else:\n","#                     dx = 0\n","#                     dy = -1\n","#             nx = min(max(0, x + dx), 9)\n","#             ny = min(max(0, y + dy), 9)\n","#             if old_image[nx, ny] < 0.5:\n","#                 new_image[nx, ny] = 1\n","#                 success = 1\n","#         return new_image\n","\n","#     images = np.zeros((20, 25, H, W), dtype=np.float32)\n","#     for i_img in range(25):\n","#         images[0, i_img, int(H / 2), int(W / 2)] = 1\n","#     for j in range(1, 20):\n","#         for i_img in range(25):\n","#             images[j, i_img, :, :] = add_pixel(images[j - 1, i_img, :, :])\n","#     images = tf.constant(images)\n","    \n","#     for i_step_v in i_step_verify:\n","#         ca, loss_log, loss_log_classes = get_model(i_step_v)\n","#         x = ca.initialize(images[0, :, :, :])\n","#         with VideoWriter(folder + '/CA/Movie_test_increase_{}_{}.mp4'.format(id_run, i_step_v)) as vid:\n","#             for j in range(20):\n","#                 x = ca.mutate(x, tf.expand_dims(images[j, :, :, :], -1))\n","#                 for i in tqdm.trange(TR_EVOLVE):\n","#                     x = ca(x)\n","#                     image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","#                     im = np.uint8(image*255)\n","#                     im = PIL.Image.fromarray(im)\n","#                     draw = PIL.ImageDraw.Draw(im)\n","#                     vid.add(np.uint8(im))\n","#         x = ca.initialize(images[0, :, :, :])\n","#         with VideoWriter(folder + '/CA/Movie_test_decrease_{}_{}.mp4'.format(id_run, i_step_v)) as vid:\n","#             for j in range(20):\n","#                 x = ca.mutate(x, tf.expand_dims(images[19 - j, :, :, :], -1))\n","#                 for i in tqdm.trange(TR_EVOLVE):\n","#                     x = ca(x)\n","#                     image = zoom(tile2d(classify_and_color(ca, x)), scale=4)\n","#                     im = np.uint8(image*255)\n","#                     im = PIL.Image.fromarray(im)\n","#                     draw = PIL.ImageDraw.Draw(im)\n","#                     vid.add(np.uint8(im))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OjQpvGShoKcO"},"source":[""],"execution_count":null,"outputs":[]}]}