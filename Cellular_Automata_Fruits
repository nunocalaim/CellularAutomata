{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Cellular_Automata_Fruits","provenance":[{"file_id":"1iXlnHxFvEt5dahFTA8i21Lvw0DyiLd-f","timestamp":1612469548949},{"file_id":"1ie8_PJUYcS7RAbAP8J_IfGTmE0K3d66P","timestamp":1611338885717},{"file_id":"1SEw3Nsw8w6boGj9trNb5hmwGr1r6Esgu","timestamp":1611144331681},{"file_id":"171_TWT-Am5hgiYyUMDstZdyzrH2nNrL0","timestamp":1610025279276},{"file_id":"1I6DNV4lsaj0Q0M7ybgeUPX40VMvmMmsv","timestamp":1609862549553},{"file_id":"1DdBgaOtQ4U7XjHOfADUJf0akIn92LUHZ","timestamp":1607705721216},{"file_id":"1L2o5A2vko0-KWNNTaELBAjjlvZ2wGN8i","timestamp":1607617282280},{"file_id":"1nvJ3L0U0FP5orhNrtx-TWm-oJ4wAbZsP","timestamp":1607613928447}],"collapsed_sections":[],"authorship_tag":"ABX9TyOwcmF7MsqwVB8A4I414EPj"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pDzbVQ_T6iBD"},"source":["# Cellular Automata on image classification.\n","\n","In this notebook we train and test Cellular Automata (CA) on a grid whose goal is to collectively decide which class an image belongs to. In this task, the inputs are grayscale images of 3 kinds of fruits: Bananas, Apples and Oranges. The goal for the CA is to globally identify the class of the images only given local information."]},{"cell_type":"code","metadata":{"id":"z-1wywoxncZg"},"source":["# Run this if you want to connect this collab notebook to your google drive (useful for saving models in training)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","folder = 'drive/MyDrive/Code/GitHub/CellularAutomata' # use whatever path the repo is found on your google drive\n","import sys\n","sys.path.insert(1, folder) # we insert the repo into the path such that we can easily import the necessary modules"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zo-knd3UDME_"},"source":["import ca_models as cam # this module contains the keras models, the loss function, etc.\n","import datasets_library as dsl # this module creates and loads the different datasets for the tasks\n","import ca_visualisation as cavis # this module is useful for visualisation of progress and producing final videos\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices()) # Useful to check if the collab is using GPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qu-zdZ8JyffI"},"source":["SEED_TRAINING = 1\n","SEED_MOVIES = 1\n","# Model Options\n","NO_NEIGHBORS = 1 # the radius for the immediate neighbors to consider # 1->3x3 neighborhood, 2->5x5, 3->7x7, 4->9x9\n","BATCH_SIZE = 64 # number of images per batch\n","LR = 1e-3 # initial learning rate\n","# Task and Dataset parameters\n","RebuildDatasetQ = False # if True we rebuild the dataset\n","ds_options = {}\n","ds_options['SEED_DATASET'] = 1\n","TR_EVOLVE = 70 # Number of time steps to let CA evolve for each input during training\n","TST_EVOLVE = 70 # Number of time steps to let CA evolve for each input during testing\n","ds_options['H'], ds_options['W'] = 20, 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6s54kJoYRbIG"},"source":["# Get the dataset\n","x_train, x_test, y_train, y_test, ds_str, NO_CLASSES, H, W, classes_labels = dsl.get_dataset('fruits', ds_options, RebuildDatasetQ, folder)\n","y_train_hot = dsl.y2yhot(x_train, y_train, NO_CLASSES, 'fruits')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Aj5M6oJxCof"},"source":["id_str = 'CA_fruits' # the prefix to all file names which will be use for saving and loading the model\n","print(id_str)\n","\n","TR_NO_ITERATIONS = 50000 # number of iterations for the training loop\n","EXPORT_EVERY = 2000 # number of iterations between each model export\n","VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","i_step_verify = [20000, 50000] #\n","\n","color_lookup = tf.constant([\n","                    [255, 0, 0], # Color for apple\n","                    [215, 252, 0], # Color for banana\n","                    [0, 0, 255], # Color for orange\n","                    [0, 0, 0], # This is the default for digits.\n","                    [255, 255, 255] # This is the background.\n","                    ])\n","\n","NO_CHANNELS = 50 # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","\n","first_point = int(TR_NO_ITERATIONS*0.3333)\n","second_point = int(TR_NO_ITERATIONS*0.6667)\n","lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([2*first_point, 2*second_point], [LR, LR*0.1, LR*0.01]) # we need to multiply by two because in each training step we perform 2 gradient descents\n","trainer = tf.keras.optimizers.Adam(lr_sched) # use ADAM optimizer with learning rate schedule\n","\n","loss_log = np.zeros(TR_NO_ITERATIONS) # for plotting of loss function across time\n","loss_log_classes = np.zeros((TR_NO_ITERATIONS, NO_CLASSES)) # for plotting of loss function across time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgNuQfis7p4g"},"source":["ca = cam.CAModel(NO_NEIGHBORS, NO_CHANNELS, NO_CLASSES, H, W, add_noise=True, model_complexity='middle', dead_pixels=False)\n","ITER = 0\n","ca.update_state.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PcMsi_PmoEVD"},"source":["# Training happens here\n","np.random.seed(SEED_TRAINING)\n","# Training Loop\n","for i in range(ITER, TR_NO_ITERATIONS):\n","    b_idx = np.random.randint(x_train.shape[0], size=BATCH_SIZE)\n","    x0 = ca.initialize_random(x_train[b_idx])\n","    y0 = y_train_hot[b_idx]\n","    y0_label = y_train[b_idx]\n","    y0_label = tf.convert_to_tensor(y0_label)        \n","\n","    x, loss, c_l = cam.train_step(trainer, ca, x0, y0, y0_label, TR_EVOLVE, NO_CLASSES)\n","\n","    loss_log[i] = loss.numpy()\n","    loss_log_classes[i, :] = [k.numpy() for k in c_l]\n","\n","    if i % EXPORT_EVERY == 0:\n","        cam.export_model(folder, id_str, ca, i, loss_log, loss_log_classes)\n","    if i % VISUALISE_EVERY == 0:\n","        clear_output()\n","        cavis.plot_loss(loss_log[:i], loss_log_classes[:i, :], folder, id_str, classes_labels, color_lookup, True)\n","\n","    print('\\r step: {}, log10(loss): {}, log10(loss)[classes]: {}'.format(i + 1, np.log10(loss), np.log10(c_l)), end='')\n","cam.export_model(folder, id_str, ca, TR_NO_ITERATIONS, loss_log, loss_log_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vV_WIAkvoGol"},"source":["if RunTestMoviesQ:\n","    eval_bs = 5 ** 2 # number of samples to show in the movie\n","    for i_step_v in i_step_verify:\n","        ca, loss_log, loss_log_classes = cam.get_model(folder, id_str, i_step_v, NO_NEIGHBORS, NO_CHANNELS, NO_CLASSES, H, W, AddNoiseQ, model_complexity, dead_pixels=dead_pixels)\n","\n","        np.random.seed(SEED_MOVIES)\n","        new_idx = np.random.randint(0, x_test.shape[0], size=eval_bs)\n","        x0 = ca.initialize_random(x_test[new_idx])\n","\n","        cavis.make_run_videos(folder, id_str, i_step_v, TST_EVOLVE, MutateTestingQ, x0, ca, color_lookup)"],"execution_count":null,"outputs":[]}]}