{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NC_CA_Emotions","provenance":[{"file_id":"1SEw3Nsw8w6boGj9trNb5hmwGr1r6Esgu","timestamp":1611144331681},{"file_id":"171_TWT-Am5hgiYyUMDstZdyzrH2nNrL0","timestamp":1610025279276},{"file_id":"1I6DNV4lsaj0Q0M7ybgeUPX40VMvmMmsv","timestamp":1609862549553},{"file_id":"1DdBgaOtQ4U7XjHOfADUJf0akIn92LUHZ","timestamp":1607705721216},{"file_id":"1L2o5A2vko0-KWNNTaELBAjjlvZ2wGN8i","timestamp":1607617282280},{"file_id":"1nvJ3L0U0FP5orhNrtx-TWm-oJ4wAbZsP","timestamp":1607613928447}],"collapsed_sections":[],"authorship_tag":"ABX9TyOUzxdD4nfT+ShVjGffNdsD"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pDzbVQ_T6iBD"},"source":["Celular Automata on a grid must collectively decide what emotions the faces are expressing\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-1wywoxncZg","executionInfo":{"status":"ok","timestamp":1611316754735,"user_tz":0,"elapsed":607,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"d274943e-d8fe-49bf-e241-9ad29c34f2b3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","folder = 'drive/MyDrive/Code/GitHub/CellularAutomata'\n","import sys\n","sys.path.insert(1, folder)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zo-knd3UDME_","executionInfo":{"status":"ok","timestamp":1611316757863,"user_tz":0,"elapsed":3728,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"e97762f8-0448-4394-d0a5-9820d15505b8"},"source":["import ca_models\n","import emotions_dataset as ds_l\n","import vis_ca\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 3806663001512084385\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14638920512\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 16549484611072597103\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EKLwI-jTx2By","executionInfo":{"status":"ok","timestamp":1611316757864,"user_tz":0,"elapsed":3723,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# import importlib\n","# importlib.reload(ca_models)\n","# importlib.reload(vis_ca)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qu-zdZ8JyffI","executionInfo":{"status":"ok","timestamp":1611316757865,"user_tz":0,"elapsed":3721,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# Type of Run\n","JustTestingCodeQ = True # If True run everything faster, for Debugging\n","SuffleLabelsQ = False # If True we randomly shuffle the labels, useful to have a notion of the parameters with noise\n","LoadPreviousModelQ = False # if True we load the model, either for further training or just testing\n","i_step_load = 1000\n","RunTrainingQ = True # If True we run the neural network training\n","RunTestMoviesQ = True # if True, in the end we test an increasing size of inputs\n","MutateTestingQ = False # if True, during testing we mutate the image\n","SEED_TRAINING = 1\n","SEED_MOVIES = 1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FamWPRoxKdg","executionInfo":{"status":"ok","timestamp":1611316757865,"user_tz":0,"elapsed":3718,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# Model Options\n","model_complexity = 'complex' # 'simplest' 'middle' 'complex'\n","NO_NEIGHBORS = 3 # the number of immediate neighbors to consider # 1 2 3 4\n","AddNoiseQ = False # if True then the normal update of the CA has noise added\n","InitializeRandomQ = False # if True, the initial state of the CA is random\n","MutateTrainingQ = False # if True, during training we mutate the image to anothe random one\n","no_channels = 'FiftyChannels' # 'SameClasses' '5PlusClasses' '4TimesClasses' 'FiftyChannels'\n","TR_EVOLVE = 50 # Number of time steps to let CA evolve for each input during training\n","TST_EVOLVE = 50 # Number of time steps to let CA evolve for each input during testing\n","BATCH_SIZE = 64 # number of images per batch\n","LR = 1e-3 # initial learning rate\n","UseLRScheduleQ = True # if True use Adam with a learning rate schedule"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wyzeUtdPt3Op","executionInfo":{"status":"ok","timestamp":1611316757867,"user_tz":0,"elapsed":3716,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# Task and Dataset\n","RebuildDatasetQ = False # if True we rebuild the dataset\n","classes_labels = ['Happy', 'Sad'] # ['Happy', 'Neutral', 'Sad', 'Fear', 'Angry', 'Surprise', 'Disgust']\n","H, W = 48, 48\n","DataAugmentationQ = True\n","DataBalancingQ = True\n","SEED_DATASET = 1"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Aj5M6oJxCof","executionInfo":{"status":"ok","timestamp":1611316757867,"user_tz":0,"elapsed":3713,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"a534439f-84d2-4f2c-d6df-7211fae01ee8"},"source":["if JustTestingCodeQ:\n","    TR_NO_ITERATIONS = 500 # number of iterations for the training loop\n","    EXPORT_EVERY = 100 # number of iterations between each model export\n","    VISUALISE_EVERY = 50 # number of iteration between each model visualisation\n","    i_step_verify = [500] # [250, 500]\n","else:\n","    TR_NO_ITERATIONS = 500000 # number of iterations for the training loop\n","    EXPORT_EVERY = 2000 # number of iterations between each model export\n","    VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","    i_step_verify = [240000, 500000] # [240000, 500000]\n","\n","    TR_NO_ITERATIONS = 5000 # number of iterations for the training loop\n","    EXPORT_EVERY = 1000 # number of iterations between each model export\n","    VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","    i_step_verify = [0, 5000] # [240000, 500000]\n","\n","    TR_NO_ITERATIONS = 20000 # number of iterations for the training loop\n","    EXPORT_EVERY = 1000 # number of iterations between each model export\n","    VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","    i_step_verify = [0, 20000] # [240000, 500000]\n","\n","    # TR_NO_ITERATIONS = 50000 # number of iterations for the training loop\n","    # EXPORT_EVERY = 2000 # number of iterations between each model export\n","    # VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","    # i_step_verify = [50000, 100000] # [240000, 500000]\n","\n","    # TR_NO_ITERATIONS = 200000 # number of iterations for the training loop\n","    # EXPORT_EVERY = 2000 # number of iterations between each model export\n","    # VISUALISE_EVERY = 500 # number of iteration between each model visualisation\n","    # i_step_verify = [100000, 200000] # [240000, 500000]\n","    \n","    #\n","if LoadPreviousModelQ and not RunTrainingQ:\n","    i_step_verify = [i_step_load]\n","\n","tc_str = str(classes_labels).replace('[', '').replace(']', '').replace(', ', '_').replace('\\'', '')\n","ds_str = 'Emotions_' + tc_str\n","if DataBalancingQ:\n","    ds_str += '_Bal'\n","if DataAugmentationQ:\n","    ds_str += '_Aug'\n","if SEED_DATASET != 1:\n","    ds_str += '_Seed{}'.format(SEED_DATASET)\n","print(ds_str)\n","id_str = 'CA_{}_Modl{}_Channels{}'.format(ds_str, model_complexity, no_channels) # the prefix to all file names which will be use for saving and loading the model\n","if AddNoiseQ:\n","    id_str += '_AddNoise'\n","if InitializeRandomQ:\n","    id_str += '_InitRnd'\n","if MutateTrainingQ:\n","    id_str += '_MutTrain'\n","if SuffleLabelsQ:\n","    id_str += '_Shuffle'\n","print(id_str)\n","\n","NO_CLASSES = len(classes_labels) # Number of classes that the CA must distinguish\n","\n","if NO_CLASSES == 1:\n","    color_lookup = tf.constant([\n","                        [255, 0, 0], #These are the colors for the different classes\n","                        [0, 0, 0], # This is for when no class is voted.\n","                        ])\n","elif NO_CLASSES == 2:\n","    color_lookup = tf.constant([\n","                        [255, 0, 0], #These are the colors for the different classes\n","                        [0, 255, 0],\n","                        [0, 0, 0], # This is for when no class is voted.\n","                        ])\n","elif NO_CLASSES == 3:\n","    color_lookup = tf.constant([\n","                        [255, 0, 0], #These are the colors for the different classes\n","                        [0, 255, 0],\n","                        [0, 0, 255],\n","                        [0, 0, 0], # This is for when no class is voted.\n","                        ])\n","elif NO_CLASSES == 5:\n","    color_lookup = tf.constant([\n","                        [255, 0, 0], #These are the colors for the different classes\n","                        [0, 255, 0],\n","                        [0, 0, 255],\n","                        [255, 255, 0],\n","                        [0, 255, 255],\n","                        [0, 0, 0], # This is for when no class is voted.\n","                        ])\n","elif NO_CLASSES == 8:\n","    color_lookup = tf.constant([\n","                        [85, 85, 85], #These are the colors for the different classes\n","                        [255, 0, 0], \n","                        [0, 255, 0],\n","                        [0, 0, 255],\n","                        [255, 255, 0],\n","                        [0, 255, 255],\n","                        [255, 0, 255],\n","                        [170, 170, 170],\n","                        [0, 0, 0], # This is for when no class is voted.\n","                        ])\n","\n","if no_channels == 'SameClasses':\n","    NO_CHANNELS = NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '4TimesClasses':\n","    NO_CHANNELS = 4 * NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == '5PlusClasses':\n","    NO_CHANNELS = 5 + NO_CLASSES # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","elif no_channels == 'FiftyChannels':\n","    NO_CHANNELS = 50 # number of hidden states of the CA, must be at least NO_CLASSES because there are two outputs\n","\n","\n","if UseLRScheduleQ:\n","    first_point = int(TR_NO_ITERATIONS*0.3333)\n","    second_point = int(TR_NO_ITERATIONS*0.6667)\n","    if LoadPreviousModelQ and RunTrainingQ:\n","        if i_step_load > second_point:\n","            trainer = tf.keras.optimizers.Adam(learning_rate=LR*0.01) # use ADAM optimizer\n","        elif i_step_load > first_point:\n","            remaining_steps = TR_NO_ITERATIONS - i_step_load\n","            lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([2 * (second_point - i_step_load)], [LR*0.1, LR*0.01]) # we need to multiply by two because in each training step we perform 2 gradient descents\n","            trainer = tf.keras.optimizers.Adam(lr_sched) # use ADAM optimizer with learning rate schedule\n","        else:\n","            lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([2 * (first_point - i_step_load), 2 * (second_point - i_step_load)], [LR, LR*0.1, LR*0.01]) # we need to multiply by two because in each training step we perform 2 gradient descents\n","    else:\n","        lr_sched = tf.keras.optimizers.schedules.PiecewiseConstantDecay([2*first_point, 2*second_point], [LR, LR*0.1, LR*0.01]) # we need to multiply by two because in each training step we perform 2 gradient descents\n","    trainer = tf.keras.optimizers.Adam(lr_sched) # use ADAM optimizer with learning rate schedule\n","else:\n","    trainer = tf.keras.optimizers.Adam(learning_rate=LR) # use ADAM optimizer\n","\n","loss_log = np.zeros(TR_NO_ITERATIONS) # for plotting of loss function across time\n","loss_log_classes = np.zeros((TR_NO_ITERATIONS, NO_CLASSES)) # for plotting of loss function across time"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Emotions_Happy_Sad_BalTrue_AugTrue_Seed1\n","CA_Emotions_Happy_Sad_BalTrue_AugTrue_Seed1_ModlComplxcomplex_AddNoiseFalse_InitRndFalse_MutTrainFalse_ChannelsFiftyChannels_ShuffleFalse\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9aZs8ebLu9Qn","executionInfo":{"status":"ok","timestamp":1611316761844,"user_tz":0,"elapsed":7684,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["# Prepare the dataset\n","BuildDS = False\n","if RebuildDatasetQ:\n","    BuildDS = True\n","else:\n","    try:\n","        res = np.load(folder + '/dataset/{}.npz'.format(ds_str))\n","        x_train, x_test, y_train, y_test = res['x_train'], res['x_test'], res['y_train'], res['y_test']\n","    except:\n","        BuildDS = True\n","if BuildDS:\n","\n","    x_train, x_test, y_train, y_test = ds_l.build_dataset(folder, classes_labels, H, W, SEED_DATASET, ds_str, DataBalancingQ, DataAugmentationQ)\n","    np.savez(folder + '/dataset/{}.npz'.format(ds_str), x_train=x_train, x_test=x_test, y_train=y_train, y_test=y_test)\n","\n","    cols=7\n","    rows=7\n","    fig, ax = plt.subplots()\n","    DISP = np.zeros((1, cols * W + 1))\n","    RES = [[0 for i in range(cols)] for j in range(rows)]\n","    for i in range(rows):\n","        disp = np.zeros((H, 1))\n","        for j in range(cols):\n","            image_idx = np.random.randint(x_train.shape[0])\n","            disp = np.hstack((disp, x_train[image_idx, :, :]))\n","            RES[i][j] = y_train[image_idx]\n","        DISP = np.vstack((DISP, disp))\n","    ax.imshow(DISP)\n","    print(np.array(RES))\n","\n","if SuffleLabelsQ:\n","    np.random.shuffle(y_train)\n","\n","y_train_hot = ds_l.y2yhot(x_train, y_train, NO_CLASSES)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5S1jVq6HrFO","executionInfo":{"status":"ok","timestamp":1611316762199,"user_tz":0,"elapsed":8036,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"9f689b0f-e707-42ba-ce2d-096fe92ac54a"},"source":["print(y_train_hot.shape, y_train.shape, np.all(np.sum(y_train_hot, axis=(1, 2, 3)) == 48 ** 2), np.max(y_train_hot), np.min(y_train_hot), np.isnan(x_train).any())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(69264, 48, 48, 2) (69264,) True 1.0 0.0 False\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxQyIu_1IEba","executionInfo":{"status":"ok","timestamp":1611316762775,"user_tz":0,"elapsed":8607,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"6bc14a40-a511-4bee-8edf-9777ad98783c"},"source":["y = 1\n","for i in range(y_train.shape[0]):\n","    y *= np.sum(y_train_hot[i, 0, 0, y_train[i]])\n","print(y)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RgNuQfis7p4g","executionInfo":{"status":"ok","timestamp":1611316769781,"user_tz":0,"elapsed":15607,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["if LoadPreviousModelQ:\n","    ca, loss_log, loss_log_classes = ca_models.get_model(folder, id_str, i_step_load, NO_NEIGHBORS, NO_CHANNELS, NO_CLASSES, H, W, AddNoiseQ, model_complexity)\n","    ITER = i_step_load + 1\n","else:\n","    ca = ca_models.CAModel(NO_NEIGHBORS, NO_CHANNELS, NO_CLASSES, H, W, add_noise=AddNoiseQ, model_complexity=model_complexity)\n","    ITER = 0"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfxS25QT9cdK","executionInfo":{"status":"ok","timestamp":1611316769785,"user_tz":0,"elapsed":15607,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"dd8c0b05-c556-42b6-f02e-bc202e554f8b"},"source":["ca.update_state.summary()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (1, 48, 48, 80)           200000    \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (1, 48, 48, 120)          9720      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (1, 48, 48, 50)           6050      \n","=================================================================\n","Total params: 215,770\n","Trainable params: 215,770\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":785},"id":"PcMsi_PmoEVD","executionInfo":{"status":"error","timestamp":1611316815360,"user_tz":0,"elapsed":61180,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}},"outputId":"9ccf740b-37ad-4638-af28-c58b76f5ed57"},"source":["# Training happens here\n","np.random.seed(SEED_TRAINING)\n","if RunTrainingQ:\n","    # Training Loop\n","    for i in range(ITER, TR_NO_ITERATIONS):\n","        b_idx = np.random.randint(x_train.shape[0], size=BATCH_SIZE)\n","        if InitializeRandomQ:\n","            x0 = ca.initialize_random(x_train[b_idx])\n","        else:\n","            x0 = ca.initialize(x_train[b_idx])\n","        y0 = y_train_hot[b_idx]\n","        y0_label = y_train[b_idx]\n","        y0_label = tf.convert_to_tensor(y0_label)        \n","\n","        x, loss, c_l = ca_models.train_step(trainer, ca, x0, y0, y0_label, TR_EVOLVE, NO_CLASSES, MutateTrainingQ=MutateTrainingQ)\n","\n","        loss_log[i] = loss.numpy()\n","        loss_log_classes[i, :] = [k.numpy() for k in c_l]\n","\n","        if i % VISUALISE_EVERY == 0:\n","            clear_output()\n","            vis_ca.plot_loss(loss_log[:i], loss_log_classes[:i, :], folder, id_str, classes_labels, color_lookup, True)\n","        if i % EXPORT_EVERY == 0:\n","            ca_models.export_model(folder, id_str, ca, i, loss_log, loss_log_classes)\n","\n","        if NO_CLASSES > 5:\n","            print('\\r step: {}, log10(loss): {}'.format(i + 1, np.log10(loss)), end='')\n","        else:\n","            print('\\r step: {}, log10(loss): {}, log10(loss)[classes]: {}'.format(i + 1, np.log10(loss), np.log10(c_l)), end='')\n","    ca_models.export_model(folder, id_str, ca, TR_NO_ITERATIONS, loss_log, loss_log_classes)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["No handles with labels found to put in legend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":[" step: 31, log10(loss): 3.0648491382598877, log10(loss)[classes]: [3.1522331 2.969749 ]"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f8181f7e2700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my0_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mca_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTR_EVOLVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNO_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMutateTrainingQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMutateTrainingQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"vV_WIAkvoGol","executionInfo":{"status":"aborted","timestamp":1611316815358,"user_tz":0,"elapsed":61175,"user":{"displayName":"Nuno Calaim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsCxTgIhzSJMrYldropFf8at3ge2yEnwJrwCpQjDw=s64","userId":"02378072602186647489"}}},"source":["if RunTestMoviesQ:\n","    eval_bs = 5 ** 2 # number of samples to show in the movie\n","    for i_step_v in i_step_verify:\n","        ca, loss_log, loss_log_classes = ca_models.get_model(folder, id_str, i_step_v, NO_NEIGHBORS, NO_CHANNELS, NO_CLASSES, H, W, AddNoiseQ, model_complexity)\n","\n","        np.random.seed(SEED_MOVIES)\n","\n","        new_idx = np.random.randint(0, x_test.shape[0] - 1, size=eval_bs)\n","        if InitializeRandomQ:\n","            x0 = ca.initialize_random(x_test[new_idx])\n","        else:\n","            x0 = ca.initialize(x_test[new_idx])\n","\n","        vis_ca.make_run_videos(folder, id_str, i_step_v, TST_EVOLVE, MutateTestingQ, x0, ca, color_lookup)"],"execution_count":null,"outputs":[]}]}